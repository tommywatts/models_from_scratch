{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations_with_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_transformation(X, degree):\n",
    "    \n",
    "    m, n = X.shape\n",
    "            \n",
    "    feature_combinations = list(chain.from_iterable(combinations_with_replacement(range(n), i)\n",
    "                                   for i in range(0, degree + 1)))\n",
    "    \n",
    "    Xn = np.zeros((m, len(feature_combinations)))\n",
    "    \n",
    "    for i, comb in enumerate(feature_combinations):\n",
    "        Xn[:, i] = np.prod(X[:, comb], axis=1)\n",
    "    \n",
    "    return Xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearBase(object):\n",
    "    \n",
    "    \"\"\"Base class for linear models\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate, n_iter):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit using gradient descent.\n",
    "        \"\"\"\n",
    "        for i in range(self.n_iter):\n",
    "\n",
    "            error = self._error(X, y, self.theta)\n",
    "\n",
    "            # update gradients \n",
    "            gradients = 2 / self.m * X.T.dot(error)\n",
    "        \n",
    "            # update theta \n",
    "            self.theta -= self.learning_rate * gradients\n",
    "            \n",
    "    def _error(self, X, y, theta):\n",
    "        return X.dot(theta) - y.reshape(-1,1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        xm, xn = X.shape\n",
    "        \n",
    "        if not self.fitted:\n",
    "            raise Exception(f\"{__class__.__name__} is not yet fitted.\")\n",
    "            \n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(1,-1)\n",
    "            \n",
    "        if xn != self.n:\n",
    "            raise Exception(f\"Input data shape must be equal to fit data shape {self.n}\")\n",
    "            \n",
    "        if xn == 1:\n",
    "            return X.dot(self.coefs) + self.intercept\n",
    "        \n",
    "        return X.dot(self.coefs)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if self.fitted:\n",
    "            return f\"coefficients: {self.coefs}, \\n\\n intercept: {self.intercept}\"\n",
    "        return self.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linreg(LinearBase):\n",
    "    \n",
    "    \"\"\" Linear Regression \"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate = 0.01, n_iter = 1000, degree=1):\n",
    "        super().__init__(learning_rate, n_iter)\n",
    "        self.degree = degree\n",
    "        self.coefs = None\n",
    "        self.intercept = None\n",
    "        self.fitted = False \n",
    "\n",
    "    def fit(self, X, y, optimization='normal'):\n",
    "        self.m, self.n = X.shape\n",
    "                 \n",
    "        # add 1s for bias or transform into polynomial features\n",
    "        if self.degree == 1:\n",
    "            xb = np.hstack((np.ones((self.m, 1)), X))\n",
    "        else:\n",
    "            xb = polynomial_transformation(X, self.degree)\n",
    "        \n",
    "        # initiate coefs\n",
    "        self.theta = np.ones((xb.shape[1], 1))\n",
    "        \n",
    "        if optimization=='normal':\n",
    "            if self.m < 50000:\n",
    "                self.theta = np.linalg.inv(xb.T.dot(xb)).dot(xb.T).dot(y)\n",
    "            else:\n",
    "                optimization = 'gradient_descent'\n",
    "        \n",
    "        if optimization=='gradient_descent':\n",
    "            \n",
    "            super().fit(xb, y)\n",
    "        \n",
    "        if optimization=='stochastic':\n",
    "            \n",
    "            for step in range(self.n_iter):\n",
    "                \n",
    "                for i in range(self.m): \n",
    "                    \n",
    "                    # random selection from input\n",
    "                    random_index = np.random.randint(self.m)\n",
    "                    xi = xb[random_index:random_index + 1]\n",
    "                    yi = y[random_index:random_index + 1]\n",
    "                    \n",
    "                    # compute error\n",
    "                    error = self._error(xi, yi, self.theta)\n",
    "                    \n",
    "                    # update gradients\n",
    "                    gradients =  2 * xi.T.dot(error)\n",
    "                \n",
    "                    # get learning rate at each iteration from the schedule\n",
    "                    eta = self._schedule(step * self.m + i)\n",
    "                    \n",
    "                    self.theta -= eta * gradients\n",
    "            \n",
    "        # fit attributes\n",
    "        self.coefs = self.theta[1:]\n",
    "        self.intercept = self.theta[0]\n",
    "        self.fitted = True\n",
    "        return self\n",
    "        \n",
    "    def _schedule(self, t, t0=5):\n",
    "        return t0 / (t + self.n_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(100, 2, noise = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Linreg(n_iter=5).fit(X, y, optimization='stochastic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73105858, 0.95257413, 0.9999546 ])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.array([1, 3, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.62442948],\n",
       "       [-89.03469734],\n",
       "       [-22.8730252 ]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.predict(X[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([31.58316197, 11.28632757, 86.77959229]), array([0.06178889]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = SGDRegressor().fit(X, y)\n",
    "lr.coef_, lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -53.46841187,   -1.26255958,   -3.50619264, -107.22320039,\n",
       "        -49.13195018,    8.90122353,   -5.46624176,   -5.76263165,\n",
       "         -0.60058568,    1.2226779 ,   -3.95663744,  -21.98989452,\n",
       "         -6.11812275,  -10.46843964,   -4.11955719,   -3.02941914,\n",
       "        -21.76152272,   -1.51295226,   -4.75491157,    6.50723268])"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37.68939268]]\n",
      "\n",
      "[37.37365461]\n"
     ]
    }
   ],
   "source": [
    "# l= 20\n",
    "\n",
    "# np.random.seed(0)\n",
    "# X = 2 - 3 * np.random.normal(0, 1, l)\n",
    "# y = X - 2 * (X ** 2) + 0.5 * (X ** 3) + np.random.normal(-3, 3, l)\n",
    "\n",
    "\n",
    "# plt.scatter(X,y, s=10)\n",
    "# plt.show()\n",
    "\n",
    "# X = X.reshape(-1,1)\n",
    "\n",
    "xbp, y = make_regression(n_samples=100, n_features=1, noise=20)\n",
    "\n",
    "m, n = X.shape\n",
    "\n",
    "# p = PolynomialFeatures(degree=2)\n",
    "\n",
    "# xbp = p.fit_transform(X)\n",
    "\n",
    "# initiate coefs\n",
    "\n",
    "theta = np.ones((xbp.shape[1], 1))\n",
    "\n",
    "for _ in range(500):\n",
    "    err = xbp.dot(theta) - y.reshape(-1, 1)\n",
    "    gradients = 2 / m * xbp.T.dot(err)\n",
    "    theta -= 0.01 * gradients\n",
    "    \n",
    "print(theta)\n",
    "print()\n",
    "print(LinearRegression().fit(xbp, y).coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -3.29215704, 10.83829796],\n",
       "       [ 1.        ,  0.79952837,  0.63924562],\n",
       "       [ 1.        , -0.93621395,  0.87649656],\n",
       "       [ 1.        , -4.7226796 , 22.30370258],\n",
       "       [ 1.        , -3.60267397, 12.97925974],\n",
       "       [ 1.        ,  4.93183364, 24.32298305],\n",
       "       [ 1.        , -0.85026525,  0.722951  ],\n",
       "       [ 1.        ,  2.45407162,  6.02246754],\n",
       "       [ 1.        ,  2.30965656,  5.3345134 ],\n",
       "       [ 1.        ,  0.76820449,  0.59013814],\n",
       "       [ 1.        ,  1.56786929,  2.4582141 ],\n",
       "       [ 1.        , -2.36282052,  5.58292081],\n",
       "       [ 1.        , -0.28311318,  0.08015307],\n",
       "       [ 1.        ,  1.63497495,  2.67314309],\n",
       "       [ 1.        ,  0.6684103 ,  0.44677233],\n",
       "       [ 1.        ,  0.99897702,  0.99795508],\n",
       "       [ 1.        , -2.48223722,  6.16150161],\n",
       "       [ 1.        ,  2.61547479,  6.84070838],\n",
       "       [ 1.        ,  1.0607969 ,  1.12529005],\n",
       "       [ 1.        ,  4.56228722, 20.81446466]])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l= 20\n",
    "\n",
    "np.random.seed(0)\n",
    "X = 2 - 3 * np.random.normal(0, 1, l)\n",
    "y = X - 2 * (X ** 2) + 0.5 * (X ** 3) + np.random.normal(-3, 3, l)\n",
    "plt.scatter(X,y, s=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -53.46841187,   -1.26255958,   -3.50619264, -107.22320039,\n",
       "        -49.13195018,    8.90122353,   -5.46624176,   -5.76263165,\n",
       "         -0.60058568,    1.2226779 ,   -3.95663744,  -21.98989452,\n",
       "         -6.11812275,  -10.46843964,   -4.11955719,   -3.02941914,\n",
       "        -21.76152272,   -1.51295226,   -4.75491157,    6.50723268])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1,1)\n",
    "\n",
    "m, n = X.shape\n",
    "\n",
    "xb = np.hstack((np.ones((m, 1)), X))\n",
    "\n",
    "xbp = polynomial_transformation(X, 2)\n",
    "\n",
    "# initiate coefs\n",
    "theta = np.ones((xbp.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(500):\n",
    "    err = xbp.dot(theta) - y.reshape(-1, 1)\n",
    "    gradients = 2 / m * xbp.T.dot(err)\n",
    "    theta -= 0.01 * gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  802.60118234],\n",
       "       [  360.65857329],\n",
       "       [12234.00939771]])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Linreg(degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-5.18885443e+08],\n",
      "       [-3.49624282e+07],\n",
      "       [-4.39528401e+07],\n",
      "       [-1.06727278e+09],\n",
      "       [-6.21227153e+08],\n",
      "       [-1.17754152e+09],\n",
      "       [-3.67010726e+07],\n",
      "       [-2.95654484e+08],\n",
      "       [-2.62431699e+08],\n",
      "       [-3.25618896e+07],\n",
      "       [-1.23338339e+08],\n",
      "       [-2.67900175e+08],\n",
      "       [-6.62899179e+06],\n",
      "       [-1.33748096e+08],\n",
      "       [-2.55421424e+07],\n",
      "       [-5.24568063e+07],\n",
      "       [-2.95508297e+08],\n",
      "       [-3.35154788e+08],\n",
      "       [-5.86545657e+07],\n",
      "       [-1.00861459e+09]]), array([[5.27632278e+08],\n",
      "       [3.55517903e+07],\n",
      "       [4.46937273e+07],\n",
      "       [1.08526380e+09],\n",
      "       [6.31699138e+08],\n",
      "       [1.19739127e+09],\n",
      "       [3.73197230e+07],\n",
      "       [3.00638341e+08],\n",
      "       [2.66855511e+08],\n",
      "       [3.31107805e+07],\n",
      "       [1.25417463e+08],\n",
      "       [2.72416131e+08],\n",
      "       [6.74073134e+06],\n",
      "       [1.36002711e+08],\n",
      "       [2.59727113e+07],\n",
      "       [5.33410762e+07],\n",
      "       [3.00489637e+08],\n",
      "       [3.40804492e+08],\n",
      "       [5.96433152e+07],\n",
      "       [1.02561676e+09]]), array([[-5.36526552e+08],\n",
      "       [-3.61510837e+07],\n",
      "       [-4.54471519e+07],\n",
      "       [-1.10355800e+09],\n",
      "       [-6.42347683e+08],\n",
      "       [-1.21757567e+09],\n",
      "       [-3.79488384e+07],\n",
      "       [-3.05706169e+08],\n",
      "       [-2.71353873e+08],\n",
      "       [-3.36689313e+07],\n",
      "       [-1.27531606e+08],\n",
      "       [-2.77008266e+08],\n",
      "       [-6.85436470e+06],\n",
      "       [-1.38295275e+08],\n",
      "       [-2.64105263e+07],\n",
      "       [-5.42402371e+07],\n",
      "       [-3.05555011e+08],\n",
      "       [-3.46549407e+08],\n",
      "       [-6.06487086e+07],\n",
      "       [-1.04290555e+09]]), array([[5.45570763e+08],\n",
      "       [3.67604829e+07],\n",
      "       [4.62132286e+07],\n",
      "       [1.12216069e+09],\n",
      "       [6.53175696e+08],\n",
      "       [1.23810027e+09],\n",
      "       [3.85885222e+07],\n",
      "       [3.10859468e+08],\n",
      "       [2.75928086e+08],\n",
      "       [3.42364836e+07],\n",
      "       [1.29681416e+08],\n",
      "       [2.81677757e+08],\n",
      "       [6.96990335e+06],\n",
      "       [1.40626541e+08],\n",
      "       [2.68557335e+07],\n",
      "       [5.51545703e+07],\n",
      "       [3.10705709e+08],\n",
      "       [3.52391191e+08],\n",
      "       [6.16710732e+07],\n",
      "       [1.06048576e+09]]), array([[-5.54767425e+08],\n",
      "       [-3.73801512e+07],\n",
      "       [-4.69922674e+07],\n",
      "       [-1.14107686e+09],\n",
      "       [-6.64186271e+08],\n",
      "       [-1.25897091e+09],\n",
      "       [-3.92390257e+07],\n",
      "       [-3.16099592e+08],\n",
      "       [-2.80579384e+08],\n",
      "       [-3.48136103e+07],\n",
      "       [-1.31867436e+08],\n",
      "       [-2.86426015e+08],\n",
      "       [-7.08739985e+06],\n",
      "       [-1.42997049e+08],\n",
      "       [-2.73084336e+07],\n",
      "       [-5.60843012e+07],\n",
      "       [-3.15943294e+08],\n",
      "       [-3.58331422e+08],\n",
      "       [-6.27106484e+07],\n",
      "       [-1.07836234e+09]])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "coefficients: [[ 1502079.87355173]\n",
       " [52186695.49842367]], \n",
       "\n",
       " intercept: [3449195.39130795]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.fit(X.reshape(-1,1), y, optimization='gradient_descent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.        ,  8.48492679, -1.62853134]), -6.119739594096433)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_, lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coefficients: [[nan]\n",
       " [nan]], \n",
       "\n",
       " intercept: [nan]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
