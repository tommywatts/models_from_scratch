{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(10000, 10, noise=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearBase' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3905e93b0b82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mRidgeReg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLinearBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"\"\"Ridge Regression\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LinearBase' is not defined"
     ]
    }
   ],
   "source": [
    "class RidgeReg(LinearBase):\n",
    "    \n",
    "    \"\"\"Ridge Regression\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate, n_iter, alpha):\n",
    "        super().__init__(learning_rate, n_iter)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X, y, optimization='normal', verbose=None):\n",
    "        self.input_dim = X.shape[1]\n",
    "        \n",
    "        # add 1s\n",
    "        xb = np.c_[np.ones((X.shape[0],1)), X]\n",
    "        \n",
    "        # initiate coefs\n",
    "        theta = np.ones((xb.shape[1], 1))\n",
    "        \n",
    "        # get m\n",
    "        m = xb.shape[0]\n",
    "        \n",
    "        # normal equation\n",
    "        if optimization=='normal':\n",
    "            if m < 50000:\n",
    "                \n",
    "                # identity matrix\n",
    "                id_m = np.eye(len(theta))\n",
    "                id_m[0][0] = 0\n",
    "                A = self.alpha * id_m  \n",
    "                \n",
    "                # coefficients\n",
    "                theta = np.linalg.inv(xb.T.dot(xb) + A).dot(xb.T).dot(y)\n",
    "            else:\n",
    "                optimization = 'gradient_descent'\n",
    "                \n",
    "        if optimization=='gradient_descent':\n",
    "            for step in range(self.n_iter):\n",
    "                \n",
    "                super().fit(xb, y)\n",
    "                \n",
    "                error = self._error(xb, y, theta)\n",
    "\n",
    "                 # update gradients \n",
    "                gradients = 2 / self.m * xb.T.dot(error) + (2 * self.alpha * theta)\n",
    "\n",
    "                # update coefficients            \n",
    "                theta -= self.alpha * gradients\n",
    "        \n",
    "        self.coefs = theta[1:]\n",
    "        self.intercept = theta[0]\n",
    "        self.fitted = True\n",
    "        return self\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearBase(object):\n",
    "    \n",
    "    \"\"\"Base class for linear models\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate, n_iter):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit using gradient descent.\n",
    "        \"\"\"\n",
    "        for i in range(self.n_iter):\n",
    "\n",
    "            error = self._error(X, y, self.theta)\n",
    "\n",
    "            # update gradients \n",
    "            gradients = 2 / self.m * X.T.dot(error)\n",
    "        \n",
    "            # update theta \n",
    "            self.theta -= self.learning_rate * gradients\n",
    "            \n",
    "    def _error(self, X, y, theta):\n",
    "        return X.dot(theta) - y.reshape(-1,1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        xm, xn = X.shape\n",
    "        \n",
    "        if not self.fitted:\n",
    "            raise Exception(f\"{__class__.__name__} is not yet fitted.\")\n",
    "            \n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(1,-1)\n",
    "            \n",
    "        if xn != self.n:\n",
    "            raise Exception(f\"Input data shape must be equal to fit data shape {self.n}\")\n",
    "            \n",
    "        if xn == 1:\n",
    "            return X.dot(self.coefs) + self.intercept\n",
    "        \n",
    "        return X.dot(self.coefs)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if self.fitted:\n",
    "            return f\"coefficients: {self.coefs}, \\n\\n intercept: {self.intercept}\"\n",
    "        return self.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LassoReg(LinearBase):\n",
    "    \n",
    "    \"\"\"LASSO Regression using coordinate gradient descent\"\"\"\n",
    "    \n",
    "    def __init__(self, n_iter=2000, alpha=1):\n",
    "        super().__init__(learning_rate=None, n_iter=1000)\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.m, self.n = X.shape\n",
    "        \n",
    "        # add 1s for intercept\n",
    "        xb = np.hstack((np.ones((self.m, 1)), X))\n",
    "            \n",
    "        # initialise theta    \n",
    "        theta = np.zeros(xb.shape[1])\n",
    "\n",
    "        # set intercept\n",
    "        theta[0] = np.sum(y - np.dot(xb[:, 1:], theta[1:])) / self.m\n",
    "        \n",
    "        for step in range(self.n_iter):\n",
    "            \n",
    "            for param in range(1, self.n):\n",
    "                \n",
    "                # temporary theta\n",
    "                theta_ = theta\n",
    "                theta_[param] = 0.0\n",
    "                \n",
    "                # residuals\n",
    "                err = y - np.dot(xb, theta_)\n",
    "                \n",
    "                # input to thresholding\n",
    "                x = np.dot(xb[:, param], err)\n",
    "                lmbda = self.alpha * self.m\n",
    "\n",
    "                # update coefficient\n",
    "                theta[param] = self._soft_thresholding(x, lmbda) / (xb[:, param] ** 2).sum()\n",
    "\n",
    "                # set intercept\n",
    "                theta[0] = np.sum(y - np.dot(xb[:, 1:], theta[1:])) / self.m\n",
    "\n",
    "    \n",
    "        self.intercept = theta[0].flatten()\n",
    "        self.coefs = theta[1:].flatten()\n",
    "        self.fitted = True\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _soft_thresholding(x, lmbda):\n",
    "        if x > 0 and lmbda < abs(x):\n",
    "            return x - lmbda\n",
    "        elif x < 0 and lmbda < abs(x):\n",
    "            return x + lmbda\n",
    "        return 0\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(1000, 20, noise=20, n_informative=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -1.51932394e-02,  8.83123564e-01, -0.00000000e+00,\n",
       "        4.27571463e-01, -0.00000000e+00,  7.06020276e+01, -2.16362444e-02,\n",
       "        6.83126342e-01,  4.08738379e+01,  8.43117818e+01, -0.00000000e+00,\n",
       "        8.70087270e+01, -2.72782849e-01,  0.00000000e+00,  6.59254854e+01,\n",
       "        0.00000000e+00, -0.00000000e+00,  1.48672026e-01,  0.00000000e+00])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "las = Lasso(alpha=.5, ).fit(X, y)\n",
    "las.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_preds = np.ones(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([350.53331548])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "las.predict(lasso_preds.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -1.51933347e-02,  8.83175608e-01,  0.00000000e+00,\n",
       "        4.27603365e-01,  0.00000000e+00,  7.06019977e+01, -2.16191739e-02,\n",
       "        6.83141256e-01,  4.08738305e+01,  8.43117835e+01,  0.00000000e+00,\n",
       "        8.70087314e+01, -2.72787620e-01,  0.00000000e+00,  6.59254885e+01,\n",
       "        0.00000000e+00,  0.00000000e+00,  1.48672118e-01,  0.00000000e+00])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "las_sct = LassoReg(alpha=.5).fit(X, y)\n",
    "las_sct.coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([350.5548238])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "las_sct.predict(lasso_preds.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test vs sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Ridge(alpha=0.5).fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.coef_, m.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = RidgeReg(learning_rate=0.1, n_iter = 1000, alpha = 0.5)\n",
    "q.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = np.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.predict(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.predict(predictors.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
